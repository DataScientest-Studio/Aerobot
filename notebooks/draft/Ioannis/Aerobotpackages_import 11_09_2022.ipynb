{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pL7DYscWMadXk5vN-4lr1DdtFDpZm-o3","timestamp":1660036766808},{"file_id":"1ZEp4JZpDayzHDaMeruxp1F9uV7EjUKBF","timestamp":1659954654096},{"file_id":"1qhXdYmJvtunv1bhivEwdLB9bbYKeIMoX","timestamp":1656941850410},{"file_id":"1rtxLNDvVau-UYbcAkUcA0GUgc78nRgIq","timestamp":1656586559783}],"collapsed_sections":["pB8SGMTD4JsN"],"authorship_tag":"ABX9TyM2laPeTUvBphRDk+MdYNRF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# ABOUT"],"metadata":{"id":"a59UKY4T2lk_"}},{"cell_type":"markdown","source":["\n","Datascientest's Datascientist continuous bootcamp - cohorte Mars2022 -  AeroBOT project\n","\n","**Tutor**\n","\n","* Alban THUET\n","\n","**Authors:**\n","\n","* [Ioannis STASINOPOULOS](https://www.linkedin.com/in/ioannis-stasinopoulos/)\n","\n","</br>\n","\n","---\n","</br>\n","\n","**Version History**\n","\n","Version | Date       | Author(s)  | Modification\n","--------|----------- | ---------  | --------------------------\n","X.X     | XX/XX/2022 | A.B        | modif\n","1.0     | 11/09/2022 | I.S        | Document creation"],"metadata":{"id":"DX2lsmPYcVwp"}},{"cell_type":"markdown","source":["This notebook tests the import of project-specifica packages (see corresponding section)"],"metadata":{"id":"vKhxiy5acdjC"}},{"cell_type":"markdown","source":["# IMPORT PACKAGES AND LOAD DATA"],"metadata":{"id":"cjRrSdqQ7llR"}},{"cell_type":"markdown","source":["## Import generic packages\n"],"metadata":{"id":"tAJ40jap2rBh"}},{"cell_type":"markdown","source":["settings for  full / patial Narrative display. Helene?\n"],"metadata":{"id":"qH7RERJu3N0Z"}},{"cell_type":"code","source":["#######################\n","# Import packages\n","#######################\n","import numpy as np\n","import seaborn as sns\n","import math # for math.pi etc.\n","import time # time code execution\n","\n","#######################\n","# Pandas\n","#######################\n","import pandas as pd\n","# Set pandas settings to show all data when using .head(), .columns etc.\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = None\n","pd.set_option(\"display.colheader_justify\",\"left\") # left-justify the print output of pandas\n","\n","### Display full columnwidth\n","# Set pandas settings to display full text columns\n","#pd.options.display.max_colwidth = None\n","# Restore pandas settings to display standard colwidth\n","pd.reset_option('display.max_colwidth')\n","\n","import itertools # Pour créer des iterateurs\n","\n","# Package to show the progression of pandas operations\n","from tqdm import tqdm\n","# from tqdm.auto import tqdm  # for notebooks\n","\n","# Create new `pandas` methods which use `tqdm` progress\n","# (can use tqdm_gui, optional kwargs, etc.)\n","tqdm.pandas()\n","# simply use .progress_apply() instead of .apply() on your pd.DataFram\n","\n","######################\n","# PLOTTING\n","######################\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# Define global plot parameters for better readability and consistency among plots\n","# A complete list of the rcParams keys can be retrieved via plt.rcParams.keys() function\n","plt.rcParams['axes.titlesize'] = 30\n","plt.rcParams['axes.labelsize'] = 23\n","plt.rcParams['xtick.labelsize'] = 23\n","plt.rcParams['ytick.labelsize'] = 23\n","plt.rc('legend', fontsize=23)    # legend fontsize\n","\n","# BOKEH \n","from bokeh.plotting import figure # Importation de la classe figure qui permet de créer un graphique bokeh.\n","from bokeh.io import  push_notebook, output_notebook, show\n","output_notebook() # permet d'afficher tous les futurs graphiques dans l'output d'une cellule jupyter. Si cette instruction n'est pas lancée, la figure s'affichera dans un nouvel onglet.\n","from bokeh.models import ColumnDataSource\n","from bokeh.transform import dodge\n","from bokeh.models.tools import HoverTool\n","\n","\n","#####################\n","# NLP \n","#####################\n","import re # for Regular Expression handling\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet') # WordNet lemmatizer\n","nltk.download('omw-1.4') # necessary for WordNet lemmatizer\n","from nltk.tokenize import word_tokenize # Usual tokenizer\n","from nltk.tokenize import TweetTokenizer # Special tokenizer;  \"we'll\", \"didn't\", etc. are considered as one word\n","from sklearn.feature_extraction.text import CountVectorizer # Vectorization\n","from nltk.corpus import stopwords # Import stopwords from nltk.corpus\n","from nltk.stem.snowball import EnglishStemmer\n","\n","###############################\n","# ML preprocessing and models\n","###############################\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import ensemble # random forest\n","from sklearn.svm import SVC\n","\n","# EVALUATION tools from sklearn\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import roc_curve, auc, multilabel_confusion_matrix, average_precision_score, precision_recall_curve, PrecisionRecallDisplay\n","\n","###############################\n","# Deep Learning\n","###############################\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Dropout, GlobalAveragePooling1D\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from tensorflow.keras import callbacks\n","\n","\n","###############################\n","# Other\n","###############################\n","import pickle as pkl # Saving data externally"],"metadata":{"id":"5_efzqI3_FPo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666524321269,"user_tz":-120,"elapsed":9243,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"82b959ea-5ae1-4bfb-e0c0-94e64798a018"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}]},{"cell_type":"markdown","source":["## Mount GDrive"],"metadata":{"id":"BfmhmLv0_Osg"}},{"cell_type":"code","source":["#@title\n","# Mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#check your present working directory \n","%pwd"],"metadata":{"id":"N_mjKklM_bJH","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1666524356748,"user_tz":-120,"elapsed":35497,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"7485f08d-ac8c-443b-ffe5-0280fd3c90e0","cellView":"form"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## Load project-specific packages & functions\n"],"metadata":{"id":"D9-ZOoJfNj8a"}},{"cell_type":"markdown","source":["Load project-specific packages from remote git repo on GitHUB."],"metadata":{"id":"qkaKhlUQNsh9"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/"],"metadata":{"id":"iluDminf22eO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666524356749,"user_tz":-120,"elapsed":17,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"fcb290f4-76a6-47d6-abc7-c5cdb9c8b8c7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["# Create temporary folders for importing the entire remote repo\n","# Ioannis tried to import only the aerobotpackages, but it reads it as a repo and does not work\n","!mkdir AeroBOTTemp -p     # temporary folder to store the repo\n","!mkdir aerobotpackages -p # temporary folder to store the aerobotpackages\n","\n","# Fetch data from Github\n","username = 'DataScientest-Studio'\n","repository = 'Aerobot'\n","git_token = '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' # will expire on 31.01.2023\n","#'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' \n","\n","!git clone https://{git_token}@github.com/{username}/{repository} ./AeroBOTTemp --dissociate\n","\n","# Copy the aerobotpackages into temp folder defined above\n","!cp ./AeroBOTTemp/aerobotpackages/* ./aerobotpackages\n","\n","# Delete temp repo folder \n","!rm AeroBOTTemp -r"],"metadata":{"id":"Oia3b2mE4WVb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666524371937,"user_tz":-120,"elapsed":15201,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"d9ac7be5-b1f5-488b-d8e6-136be7eb17e7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path './AeroBOTTemp' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["# Import project-specific packages\n","import aerobotpackages\n","# this automatically imports subpackages"],"metadata":{"id":"T5QKAi_cSKpf","executionInfo":{"status":"ok","timestamp":1666524371938,"user_tz":-120,"elapsed":9,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Test: Call the dummy function Aerobot_funct in 2 ways:\n","from aerobotpackages import Aerobot_funct\n","Aerobot_funct()\n","\n","# OR\n","aerobotpackages.Aerobot_funct()\n","\n","# should print 2x: 'I am a custom-defined function defined in the project Aerobot'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiE7x7a1-hlL","executionInfo":{"status":"ok","timestamp":1666524371939,"user_tz":-120,"elapsed":8,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"ad6af27a-f6eb-49ff-b6a5-6f8e849ab53a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["I am a custom-defined function defined in the project Aerobot\n","I am a custom-defined function defined in the project Aerobot\n"]}]},{"cell_type":"code","source":["# After the import, delete the packages folder\n","# This does not affect the imported packages\n","!rm aerobotpackages -r"],"metadata":{"id":"tViL-kgT3MTg","executionInfo":{"status":"ok","timestamp":1666524372376,"user_tz":-120,"elapsed":443,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Explicit loading of project-specific functions"],"metadata":{"id":"AQEjc1N_aX2V"}},{"cell_type":"code","source":["from aerobotpackages import plot_train_history\n","# this explicit import is necessary to avoid typing \n","# aerobotpackages.plot_train_history(...)\n","# at each function call"],"metadata":{"id":"vxqGJAGoQsea","executionInfo":{"status":"ok","timestamp":1666524372377,"user_tz":-120,"elapsed":14,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":8,"outputs":[]}]}