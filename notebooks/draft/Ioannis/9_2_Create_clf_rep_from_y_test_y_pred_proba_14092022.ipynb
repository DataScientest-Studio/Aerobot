{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1unsw5ueGRTaIfGrUPWxzfRw66QLNhBP2","timestamp":1658931131821},{"file_id":"1qhXdYmJvtunv1bhivEwdLB9bbYKeIMoX","timestamp":1656941850410},{"file_id":"1rtxLNDvVau-UYbcAkUcA0GUgc78nRgIq","timestamp":1656586559783}],"collapsed_sections":["BfmhmLv0_Osg"],"toc_visible":true,"authorship_tag":"ABX9TyOSZ6r3rYdq1wLGUD04OAyx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# ABOUT"],"metadata":{"id":"a59UKY4T2lk_"}},{"cell_type":"markdown","source":["\n","Datascientest's Datascientist continuous bootcamp - cohorte Mars2022 -  AeroBOT project\n","\n","**Tutor**\n","\n","* Alban THUET\n","\n","**Authors:**\n","\n","* Hélène ASSIR\n","* Hichem HADJI  \n","* [Ioannis STASINOPOULOS](https://www.linkedin.com/in/ioannis-stasinopoulos/)\n","\n","</br>\n","\n","---\n","</br>\n","\n","**Version History**\n","\n","Version | Date       | Author(s)  | Modification\n","--------|----------- | ---------  | --------------------------\n","X.X     | XX/XX/2022 | A.B        | modif\n","1.0     | 14/09/2022 | I.S        | Document creation"],"metadata":{"id":"DX2lsmPYcVwp"}},{"cell_type":"markdown","source":["This notebook creates classification reports in two formats (dictionnary and pd.DataFrame) from .pkl files containing `y_pred_proba` and `y_test`.\n","\n","Reason: Ioannis had saved only the model, `y_pred_proba` and `y_test` when running his BERT experiments. Hence, the classif reports had to be recreated.\n","\n","**Note that the clf_rep in pd.DataFrame format contains metadata, i.e. experiment parameters.**\n","\n","Only after having run several BERT experiments, became clear what the tuning parameters should be, hence we could not have predicted the columns to include in the pd.DataFrame from the beginning."],"metadata":{"id":"vKhxiy5acdjC"}},{"cell_type":"markdown","source":["# IMPORT PACKAGES\n"],"metadata":{"id":"tAJ40jap2rBh"}},{"cell_type":"code","source":["#@title Import packages\n","#######################\n","# Import packages\n","#######################\n","import numpy as np\n","import seaborn as sns\n","import math # for math.pi etc.\n","import time # time code execution\n","\n","#######################\n","# Pandas\n","#######################\n","import pandas as pd\n","# Set pandas settings to show all data when using .head(), .columns etc.\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = None\n","pd.set_option(\"display.colheader_justify\",\"left\") # left-justify the print output of pandas\n","\n","### Display full columnwidth\n","# Set pandas settings to display full text columns\n","#pd.options.display.max_colwidth = None\n","# Restore pandas settings to display standard colwidth\n","pd.reset_option('display.max_colwidth')\n","\n","import itertools # Pour créer des iterateurs\n","\n","# Package to show the progression of pandas operations\n","from tqdm import tqdm\n","# from tqdm.auto import tqdm  # for notebooks\n","\n","# Create new `pandas` methods which use `tqdm` progress\n","# (can use tqdm_gui, optional kwargs, etc.)\n","tqdm.pandas()\n","# simply use .progress_apply() instead of .apply() on your pd.DataFram\n","\n","######################\n","# PLOTTING\n","######################\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# Define global plot parameters for better readability and consistency among plots\n","# A complete list of the rcParams keys can be retrieved via plt.rcParams.keys() function\n","plt.rcParams['axes.titlesize'] = 30\n","plt.rcParams['axes.labelsize'] = 23\n","plt.rcParams['xtick.labelsize'] = 23\n","plt.rcParams['ytick.labelsize'] = 23\n","plt.rc('legend', fontsize=23)    # legend fontsize\n","\n","# BOKEH \n","from bokeh.plotting import figure # Importation de la classe figure qui permet de créer un graphique bokeh.\n","from bokeh.io import  push_notebook, output_notebook, show\n","output_notebook() # permet d'afficher tous les futurs graphiques dans l'output d'une cellule jupyter. Si cette instruction n'est pas lancée, la figure s'affichera dans un nouvel onglet.\n","from bokeh.models import ColumnDataSource, Label\n","from bokeh.transform import dodge\n","from bokeh.models.tools import HoverTool\n","\n","\n","###############################\n","# Other\n","###############################\n","import pickle as pkl # Saving data externally\n","from sklearn.metrics import classification_report, confusion_matrix"],"metadata":{"id":"5_efzqI3_FPo","cellView":"form","executionInfo":{"status":"ok","timestamp":1663245994946,"user_tz":-180,"elapsed":249,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## Mount GDrive"],"metadata":{"id":"BfmhmLv0_Osg"}},{"cell_type":"code","source":["#@title\n","# Mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#check your present working directory \n","%pwd"],"metadata":{"id":"N_mjKklM_bJH","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1663245997288,"user_tz":-180,"elapsed":1947,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"d18a6236-e741-400a-bc31-f0ccc0927c2f","cellView":"form"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/data/saved models/Yannis/BERT/7_3_9_3_UNfrozen_2022_09_14'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["#@title\n","# move to the transformed data location (you can create a deeper structure, if needed, e.g. to save a trained model):\n","%cd /content/drive/MyDrive/data/transformed/"],"metadata":{"id":"S72xAGPS_bGM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663245997289,"user_tz":-180,"elapsed":9,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"c6b53e54-ef4d-4284-a9a0-f5293b8249d9","cellView":"form"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/transformed\n"]}]},{"cell_type":"code","source":["#@title\n","!ls # list the content of the pwd\n","\n","#!ls \"/content/drive/MyDrive/Data_Science/Formations/DataScienceTest/projet/AeroBot/\" # list contect of a speficic folder"],"metadata":{"id":"NkiTSU2c_bDh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663245997551,"user_tz":-180,"elapsed":269,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"c42e39cc-c6b0-4775-9682-ac4b641c8cbf","cellView":"form"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":[" 2022_09_11_7_4_3_raw_narr_BERT_BASE_frozen_max_length_345.pkl\n"," complaints-2022-08-05_13_55.csv\n","'Copy of Qualified abbreviations_20220718.xlsx.gsheet'\n","'Data Dictionnary.xlsx'\n"," data_for_BERT_multilabel_20220805.pkl\n"," logs\n"," model.png\n"," model_results\n"," Narrative_PP_stemmed_24072022_TRAIN.pkl\n"," Narrative_Raw_Stemmed_24072022_TRAIN.pkl\n"," Narrative_RegEx_subst_21072022_TRAIN.pkl\n","'Qualified abbreviations_20220707_test.csv'\n","'Qualified abbreviations_20220708.csv'\n","'Qualified abbreviations_20220718.csv'\n","'Qualified abbreviations_20220718_Google_sheet.gsheet'\n"," test_data_final.pkl\n"," train_data_final.pkl\n"]}]},{"cell_type":"markdown","source":["# Create classification report\n","I had saved only the model, `y_pred_proba` and `y_test`.\n","Hence, we have to create the classif report."],"metadata":{"id":"SsZCJOxDKVGS"}},{"cell_type":"markdown","source":["## Function definitions"],"metadata":{"id":"G5cmN6l-Jt42"}},{"cell_type":"code","source":["def get_filenames_in_dir(dir, extension = '.pkl', include_path = False):\n","  '''\n","  Find all .pkl (or other format's) files in the directory and create a list with their names\n","  \n","  Input: \n","  - directory\n","  - file extension type\n","  - include_path: whether to include the entire path in the filename; default: False\n","  \n","  Return:\n","  - list of .pkl\n","  '''\n","  import os\n","  files_to_import = []\n","  # traverse whole directory\n","  for root, dirs, files in os.walk(dir):\n","      # select file name\n","      for file in files:\n","          # check the extension of files\n","          if file.endswith(extension):\n","            if include_path == True:\n","              files_to_import.append(os.path.join(root, file)) # print whole path of files\n","            else:  \n","              files_to_import.append(os.path.join('', file))\n","  \n","  return files_to_import"],"metadata":{"id":"qeMFuUgX1UXL","executionInfo":{"status":"ok","timestamp":1663245997552,"user_tz":-180,"elapsed":9,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def y_prob_to_y_pred_ML(y_pred_proba, threshold = 0.5):\n","  \"\"\"\n","  Converts probabilities into 0's and 1's. We are still in the MULTILABEL context.\n","  Input: MULTILABEL predictions (probabilities whose sum for each sample may exceed > 1) coming directly from the model\n","  Using a user-defined threshold, return a MULTILABEL prediction vector 'y_pred' containing 0's and 1's\n","  \"\"\"\n","  y_pred=[]\n","  for sample in y_pred_proba:\n","    y_pred.append([1 if i>= threshold else 0 for i in sample])\n","  y_pred = np.array(y_pred)\n","\n","  return y_pred"],"metadata":{"id":"ZYsdoKtEJyo7","executionInfo":{"status":"ok","timestamp":1663245997553,"user_tz":-180,"elapsed":9,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["def create_clf_rep_dict_from_saved_y_test_y_pred_proba(dir, threshold = 0.5):\n","  '''\n","  - Load y_test and y_pred_proba from their respective .pkl files, located in dir\n","  - Calculate y_pred from y_pred_proba using the function y_prob_to_y_pred_ML()\n","  - Create a classification report\n","\n","  Return a classification report 'clf_rep' in dictionnary format.\n","  '''\n","\n","  # Import DataFrames into a list 'files_to_import'\n","  %cd $dir\n","  # the '$' extracts the value from the string. Don't put any comments in the line above\n","\n","  files_to_import = get_filenames_in_dir(dir, extension = '.pkl', include_path = False)\n","\n","  print('\\nFiles found:')\n","  for filename in files_to_import:\n","    print(filename)\n","\n","  # Load y_test\n","  filename = files_to_import[1]\n","  with open(filename, \"rb\") as f:\n","    y_test = pkl.load(f)\n","\n","  # Load y_pred_proba\n","  filename = files_to_import[2]\n","  with open(filename, \"rb\") as f:\n","    y_pred_proba = pkl.load(f)\n","\n","  # Calculate y_pred given a specific threshold\n","  y_pred = y_prob_to_y_pred_ML(y_pred_proba, threshold = threshold)\n","\n","  anomalies = ['Anomaly_Aircraft Equipment', \n","              'Anomaly_Airspace Violation',\n","              'Anomaly_ATC Issue', \n","              'Anomaly_Flight Deck / Cabin / Aircraft Event',\n","              'Anomaly_Conflict', \n","              'Anomaly_Deviation - Altitude',\n","              'Anomaly_Deviation - Speed', \n","              'Anomaly_Deviation - Track / Heading',\n","              'Anomaly_Deviation / Discrepancy - Procedural',\n","              'Anomaly_Ground Excursion', \n","              'Anomaly_Ground Incursion',\n","              'Anomaly_Ground Event / Encounter',\n","              'Anomaly_Inflight Event / Encounter',\n","              'Anomaly_No Specific Anomaly Occurred']\n","  # I got this list from df.columns\n","  # 14 labels\n","\n","  clf_rep = classification_report(y_test, y_pred, output_dict = True)\n","  print(f\"\\n\\n Classification Report: \\n {classification_report(y_test, y_pred, target_names = anomalies)}\\n\")\n","\n","  return clf_rep"],"metadata":{"id":"puQHUN0fzFje","executionInfo":{"status":"ok","timestamp":1663245997554,"user_tz":-180,"elapsed":10,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["  anomalies = ['Anomaly_Aircraft Equipment', \n","              'Anomaly_Airspace Violation',\n","              'Anomaly_ATC Issue', \n","              'Anomaly_Flight Deck / Cabin / Aircraft Event',\n","              'Anomaly_Conflict', \n","              'Anomaly_Deviation - Altitude',\n","              'Anomaly_Deviation - Speed', \n","              'Anomaly_Deviation - Track / Heading',\n","              'Anomaly_Deviation / Discrepancy - Procedural',\n","              'Anomaly_Ground Excursion', \n","              'Anomaly_Ground Incursion',\n","              'Anomaly_Ground Event / Encounter',\n","              'Anomaly_Inflight Event / Encounter',\n","              'Anomaly_No Specific Anomaly Occurred']"],"metadata":{"id":"MijkUFPMWTpV","executionInfo":{"status":"ok","timestamp":1663245997555,"user_tz":-180,"elapsed":10,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Import files"],"metadata":{"id":"JhWQXpzGUUVF"}},{"cell_type":"markdown","source":["### clf_rep as dictionnary"],"metadata":{"id":"vVJ4b40fhPk1"}},{"cell_type":"code","source":["# Call the function\n","experiment_name = '2022_09_15_7_3_9_4_UNfrozen_random_state_222'\n","dir = '/content/drive/MyDrive/data/saved models/Yannis/BERT/' + experiment_name\n","\n","clf_rep = create_clf_rep_dict_from_saved_y_test_y_pred_proba(dir, threshold = 0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"YcZH3oqCU7oY","executionInfo":{"status":"error","timestamp":1663246041392,"user_tz":-180,"elapsed":43846,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"1dd82ada-6fe6-441b-a974-c147f3efc306"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/saved models/Yannis/BERT/2022_09_15_7_3_9_4_UNfrozen_random_state_222\n","\n","Files found:\n","y_pred_proba_2022_09_15_7_3_9_4_UNfrozen_random_state_222.pkl\n","y_test_2022_09_15_7_3_9_4_UNfrozen_random_state_222.pkl\n","2022_09_15_7_3_9_4_UNfrozen_random_state_222.pkl\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-2571ef27b1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/data/saved models/Yannis/BERT/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_clf_rep_dict_from_saved_y_test_y_pred_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-45-7e9173ee5517>\u001b[0m in \u001b[0;36mcreate_clf_rep_dict_from_saved_y_test_y_pred_proba\u001b[0;34m(dir, threshold)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles_to_import\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;31m# Calculate y_pred given a specific threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/pickle_utils.py\u001b[0m in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m           \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    571\u001b[0m                   \u001b[0;34m\"Entire first structure:\\n%s\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                   % (str(e), str1, str2))\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(({'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}, None, None, None, None, None, None, None, None, None, None, None, None, False), {})\n\nSecond structure: type=tuple str=((TensorSpec(shape=(None, 200), dtype=tf.int32, name='input_ids'), None, None, None, None, None, None, None, None, None, None, None, None, False), {})\n\nMore specifically: Substructure \"type=dict str={'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(None, 200), dtype=tf.int32, name='input_ids')\" is not\nEntire first structure:\n(({'input_ids': .}, ., ., ., ., ., ., ., ., ., ., ., ., .), {})\nEntire second structure:\n((., ., ., ., ., ., ., ., ., ., ., ., ., .), {})"]}]},{"cell_type":"markdown","source":["### clf_rep as pd.DataFrame"],"metadata":{"id":"k7JAhKMjhWWQ"}},{"cell_type":"code","source":["def convert_clf_rep_to_df_multilabel_BERT(clf_rep):\n","  '''\n","  Basically returns the classification report in form of a pd.DataFrame.\n","  Tailored for extracting MULTILABEL BERT experiment results.\n","  \n","  Input: \n","  - multilabel classification report in dictionary format\n","  (does not contain '0' and '1' keys)\n","\n","  Returns:\n","  - classification report in form of a pd.DataFrame\n","  '''\n","\n","  # write classification report dictionnary into pd.DataFrame\n","  metrics = pd.DataFrame(clf_rep)\n","\n","  # The rest of the code is basically kind of 'transposing' the format \n","  # and adding extra columns with parameter values\n","\n","  # Rename columns with anomaly names\n","  # Crete dictionary with correspondance among label indices and anomaly names\n","  anomaly_labels = dict(zip(metrics.columns[0:14], anomalies))\n","  metrics = metrics.rename(columns = anomaly_labels)\n","\n","  ##########################################################\n","  # Create DataFrame in the right format for the plotting of results\n","  clf_rep_df = pd.DataFrame()\n","  for anomaly in metrics.columns[0:14]:\n","\n","    temp_df = pd.DataFrame(index = metrics.index) # create temporary DataFrame with the 4 metrics as index\n","    temp_df['values'] = metrics.filter(items = [anomaly]).values # write the 4 values for the selected anomaly\n","    temp_df['anomaly'] = anomaly # fill in the column with the selected anomaly label\n","    clf_rep_df = pd.concat([clf_rep_df, temp_df])\n","\n","  clf_rep_df = clf_rep_df.reset_index().rename(columns = {'index': 'metric'})\n","\n","  # Fill in additionnal columns with metadata\n","  clf_rep_df['classifier'] = 'BERT_BASE'        # 'BERT_BASE' or 'DistilBERT' \n","  clf_rep_df['preprocessing'] = 'raw'           # 'raw' or 'raw_stem' or 'PP'\n","  clf_rep_df['undersampling'] = 0               # 1 if undersampling was applied\n","\n","  # layers run from 1 to 12\n","  clf_rep_df['UNfrozen_layers'] = '9_10_11_12'     # last 4 layers = '9_10_11_12', 'NO' if all layers frozen\n","  clf_rep_df['concat_layers']   = 'NO'       # '8_9_10_11' or 'NO' if no layers concatenation\n","  \n","  clf_rep_df['comments'] = 'last_hidden_state_CLS_random_state_222' # misc. comments, e.g. 'Flatten layer X' or 'max_length_345' or 'last_hidden_state_CLS'\n","  clf_rep_df['experiment_ID'] = '7_3_9_4'              # e.g. '7_5_2_1' if available\n","  #clf_rep_df['padding'] = padding              # 'pre' or 'post'\n","  #clf_rep_df['truncating'] = truncating        # 'pre' or 'post'\n","  #clf_rep_df['maxlen'] = maxlen   \n","  #clf_rep_df['num_words'] = num_words \n","\n","  # Reorder columns\n","  clf_rep_df = clf_rep_df[[\\\n","                           'experiment_ID',\n","                           'classifier', \n","                           'preprocessing', \n","                           'undersampling',\n","                           'UNfrozen_layers',\n","                           'concat_layers',\n","                           'comments',\n","                           'anomaly', \n","                           #'num_words', \n","                           #'maxlen', \n","                           #'padding', \n","                           #'truncating', \n","                           'metric', \n","                           'values']]\n","\n","  print(\"DataFrame length:\", len(clf_rep_df)) #should be 56 = 14 anomalies * 4 metrics\n","\n","  return clf_rep_df"],"metadata":{"id":"3QVL0Li3OYh-","executionInfo":{"status":"aborted","timestamp":1663246041393,"user_tz":-180,"elapsed":7,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the classification report into pd.DataFrame format \n","clf_rep_df = convert_clf_rep_to_df_multilabel_BERT(clf_rep)\n","clf_rep_df.head(5)"],"metadata":{"id":"LMpj17HmOwDt","executionInfo":{"status":"aborted","timestamp":1663246041394,"user_tz":-180,"elapsed":7,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save the clf reports as .pkl"],"metadata":{"id":"h-V_dndbOT2H"}},{"cell_type":"code","source":["# Save classif report to the pwd in 2 formats (dict, DataFrame)\n","!pwd\n","filename = 'clf_rep_' + experiment_name + '.pkl'\n","pkl.dump(clf_rep, open(filename, 'wb'))\n","\n","filename = 'clf_rep_df_' + experiment_name + '.pkl'\n","pkl.dump(clf_rep_df, open(filename, 'wb'))"],"metadata":{"id":"njR9umStN3pQ","executionInfo":{"status":"aborted","timestamp":1663246041395,"user_tz":-180,"elapsed":8,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NI6sob3cWWX3","executionInfo":{"status":"aborted","timestamp":1663246041396,"user_tz":-180,"elapsed":9,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"execution_count":null,"outputs":[]}]}