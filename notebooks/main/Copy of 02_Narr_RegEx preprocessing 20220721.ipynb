{"cells":[{"cell_type":"markdown","metadata":{"id":"a59UKY4T2lk_"},"source":["# ABOUT"]},{"cell_type":"markdown","metadata":{"id":"DX2lsmPYcVwp"},"source":["\n","Datascientest's Datascientist continuous bootcamp - cohorte Mars2022 -  AeroBOT project\n","\n","**Tutor**\n","\n","* Alban THUET\n","\n","**Authors:**\n","\n","* Hélène ASSIR\n","* Hichem HADJI  \n","* [Ioannis STASINOPOULOS](https://www.linkedin.com/in/ioannis-stasinopoulos/)\n","\n","</br>\n","\n","---\n","</br>\n","\n","**Version History**\n","\n","Version | Date       | Author(s)  | Modification\n","--------|----------- | ---------  | --------------------------\n","X.X     | XX/XX/2022 | A.B        | modif\n","1.2     | 26/07/2022 | I.S        | Add substitution of AM.  \n","1.1     | 22/07/2022 | I.S, H.A.  | Special treatment of narratives using RegEx's "]},{"cell_type":"markdown","metadata":{"id":"vKhxiy5acdjC"},"source":["This notebook can be executed entirely. \n","\n","It\n","\n","* mounts the GDrive of our AeroBot project @gmail account.\n","\n","* loads the data from the `train_data_final.pkl` file (cf. `0_test_set_creator_DO_NOT_MODIFY_20220630.ipynb`) under a pandas DataFrame named `df`, which contains `97417` entries and 96 columns.\n","These data do not contain any more UAS-related entries.\n","\n","* Processes Narratives according to RegEx's and saves the output into a new column. This column is saved at the end into a .pkl file for loading them into other code."]},{"cell_type":"markdown","metadata":{"id":"tAJ40jap2rBh"},"source":["# IMPORT PACKAGES\n"]},{"cell_type":"markdown","metadata":{"id":"qH7RERJu3N0Z"},"source":["settings for  full / patial Narrative display. Helene?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1658485467730,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"},"user_tz":-180},"id":"5_efzqI3_FPo","outputId":"1a6aa303-ad13-47af-b179-d4619e8f3e6d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["#######################\n","# Import packages\n","#######################\n","import numpy as np\n","import seaborn as sns\n","\n","#######################\n","# Pandas\n","#######################\n","import pandas as pd\n","# Set pandas settings to show all data when using .head(), .columns etc.\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = None\n","pd.set_option(\"display.colheader_justify\",\"left\") # left-justify the print output of pandas\n","\n","### Display full columnwidth\n","# Set pandas settings to display full text columns\n","#pd.options.display.max_colwidth = None\n","# Restore pandas settings to display standard colwidth\n","pd.reset_option('display.max_colwidth')\n","\n","import itertools # Pour créer des iterateurs\n","\n","######################\n","# PLOTTING\n","######################\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# Define global plot parameters for better readability and consistency among plots\n","# A complete list of the rcParams keys can be retrieved via plt.rcParams.keys() function\n","plt.rcParams['axes.titlesize'] = 30\n","plt.rcParams['axes.labelsize'] = 23\n","plt.rcParams['xtick.labelsize'] = 23\n","plt.rcParams['ytick.labelsize'] = 23\n","plt.rc('legend', fontsize=23)    # legend fontsize\n","\n","# BOKEH \n","from bokeh.plotting import figure # Importation de la classe figure qui permet de créer un graphique bokeh.\n","from bokeh.io import  push_notebook, output_notebook, show\n","output_notebook() # permet d'afficher tous les futurs graphiques dans l'output d'une cellule jupyter. Si cette instruction n'est pas lancée, la figure s'affichera dans un nouvel onglet.\n","from bokeh.models import ColumnDataSource\n","from bokeh.transform import dodge\n","from bokeh.models.tools import HoverTool\n","\n","#####################\n","# NLP \n","#####################\n","import re # for Regular Expression handling\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet') # WordNet lemmatizer\n","nltk.download('omw-1.4') # necessary for WordNet lemmatizer\n","from nltk.tokenize import word_tokenize # Usual tokenizer\n","from nltk.tokenize import TweetTokenizer # Special tokenizer;  \"we'll\", \"didn't\", etc. are considered as one word\n","from sklearn.feature_extraction.text import CountVectorizer # Vectorization\n","from nltk.corpus import stopwords # Import stopwords from nltk.corpus\n","\n","###############################\n","# ML preprocessing and models\n","###############################\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","import pickle as pkl # Saving data externally"]},{"cell_type":"markdown","metadata":{"id":"cjRrSdqQ7llR"},"source":["# LOAD DATA"]},{"cell_type":"markdown","metadata":{"id":"BfmhmLv0_Osg"},"source":["## Mount GDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626,"status":"ok","timestamp":1658485469637,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"},"user_tz":-180},"id":"N_mjKklM_bJH","outputId":"cc78cfea-699d-466d-a0db-ee24f0456c3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/data/transformed'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["#@title\n","# Mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#check your present working directory \n","%pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1658485469637,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"},"user_tz":-180},"id":"S72xAGPS_bGM","outputId":"f432acfe-ea0b-4a8e-900a-45e8f5872f35"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/transformed\n"]}],"source":["#@title\n","# move to the transformed data location (you can create a deeper structure, if needed, e.g. to save a trained model):\n","%cd /content/drive/MyDrive/data/transformed/"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1658485470008,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"},"user_tz":-180},"id":"NkiTSU2c_bDh","outputId":"bcc0ffa2-1379-4681-b4f1-6763337447ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["'Copy of Qualified abbreviations_20220718.xlsx.gsheet'\n","'Data Dictionnary.xlsx'\n"," Narrative_PP_stemmed_21072022_TRAIN.pkl\n"," Narrative_Raw_Stemmed_21072022_TRAIN.pkl\n","'Qualified abbreviations_20220707_test.csv'\n","'Qualified abbreviations_20220708.csv'\n","'Qualified abbreviations_20220718.csv'\n","'Qualified abbreviations_20220718_Google_sheet.gsheet'\n"," test_data_final.pkl\n"," train_data_final.pkl\n"]}],"source":["#@title\n","!ls # list the content of the pwd\n","\n","#!ls \"/content/drive/MyDrive/Data_Science/Formations/DataScienceTest/projet/AeroBot/\" # list contect of a speficic folder"]},{"cell_type":"markdown","metadata":{"id":"pB8SGMTD4JsN"},"source":["## Load data from .pkl file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":988,"status":"ok","timestamp":1658485470992,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"},"user_tz":-180},"id":"wn8QxqqiREil","outputId":"1f48fc14-5561-4c70-d9b3-dcc4e8f78271"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/transformed\n","\n","A Dataframe with 97417 entries has been loaded\n"]}],"source":["#@title\n","# Load the TRAIN data (97417 entries)\n","# Do not touch the TEST data until the end of the project!\n","# or the curse of the greek gods will fall upon you!\n","\n","%cd /content/drive/MyDrive/data/transformed/\n","with open(\"train_data_final.pkl\", \"rb\") as f:\n","    loaded_data = pkl.load(f)\n","\n","df = loaded_data[0]\n","print(\"\\nA Dataframe with\", len(df), \"entries has been loaded\")"]},{"cell_type":"markdown","metadata":{"id":"2RgOqYV9ybVf"},"source":["# NARRATIVE PREPROCESSING\n"]},{"cell_type":"markdown","metadata":{"id":"YhTQrEZR0aHl"},"source":[]},{"cell_type":"markdown","metadata":{"id":"uKrpePQkypyn"},"source":["## On narratives : ReGex (1-letter & Units)\n"]},{"cell_type":"markdown","metadata":{"id":"rFCxXH_kUlxl"},"source":["### Verify GPU activation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658485470993,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"},"user_tz":-180},"id":"Hex9jDiLUq8W","outputId":"4a4fc12d-0a0d-415e-9b9b-5e973f9884c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Default GPU Device:/device:GPU:0\n"]}],"source":["# Verify GPU is active on Google Colab\n","import tensorflow as tf \n","if tf.test.gpu_device_name(): \n","    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please change your hardware accelerator\")"]},{"cell_type":"markdown","metadata":{"id":"_ZEgSkZ6U3IM"},"source":["### Perform substitutions "]},{"cell_type":"markdown","source":["#### All except 'IF' & only AM preceeded by num"],"metadata":{"id":"7HEaeit8U0oA"}},{"cell_type":"markdown","source":["/!\\ takes time to execute!"],"metadata":{"id":"Sq_HCMlAUyEm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6P_6H7FQKez"},"outputs":[],"source":["# Compile Regular Expressions\n","r_R_L_C = re.compile(r\"\"\"\n","                  (?i)                   # turns on the case-insensitive mode of RegEx\n","                  \\d+R \n","                  | \n","                  \\d+L                   # at least a number *before* 'R' or 'L' or 'C'\n","                  |\n","                  \\d+C\n","                  \"\"\", re.VERBOSE)\n","\n","r_Right_Left_Center = re.compile(r\"\"\"\n","                  (?i)                   # turns on the case-insensitive mode of RegEx\n","                  \\d+ Right \n","                  | \n","                  \\d+ Left               # at least a number *before*\n","                  |\n","                  \\d+ Center\n","                  \"\"\", re.VERBOSE)\n","\n","r_Celcius_neg = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\s                            # Avoid finding an aircraft model type, e.g. 'MH-65C'\n","                  -                             # Our hypothesis: most temp. indications are negative\n","                                                # otherwise confustion with RWY indication '36C' (center)\n","                  \\d+                           \n","                  C\n","                  \\s                            \n","                \"\"\", re.VERBOSE)\n","\n","r_Celcius_degrees = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d+\n","                  \\s                           \n","                  degrees                       # appears mostly in plural form\n","                  \\s* \n","                  C\n","                  \\s                            # without this, you will match '120 degree clearing turn' \n","                \"\"\", re.VERBOSE)\n","\n","r_Mach_1 = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  Mach\n","                  \\s*\n","                  0*\\.\\d{1,}                    # decimal number *after* 'Mach'\n","                  \"\"\", re.VERBOSE)\n","\n","r_Mach_2 = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  0*\\.\\d{1,}                    # decimal number *before* 'Mach'\n","                  \\s*\n","                  Mach\n","                  \"\"\", re.VERBOSE)\n","\n","r_gust = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d+\n","                  g\n","                  \\d+\n","                  \"\"\", re.VERBOSE)\n","\n","# 0000Z format\n","r_Z_1 = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\s\n","                  \\d{4,4}                       # exactly 4 digits preceeding Zulu time (UTC +0) 'Z'    \n","                  Z\n","                  \\s                            \n","                  \"\"\", re.VERBOSE)\n","\n","# 00:00Z format\n","r_Z_2 = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\s\n","                  \\d{2,2}                       # exactly 2 digits     \n","                  \\:\n","                  \\d{2,2}\n","                  Z\n","                  \\s                            \n","                  \"\"\", re.VERBOSE)\n","\n","r_KTS = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d+\n","                  KTS\n","                  |\n","                  \\d+\n","                  KT                        \n","                \"\"\", re.VERBOSE)\n","\n","r_alt_1 = re.compile(r\"\"\"\n","                    (?i)                         # turns on the case-insensitive mode of RegEx\n","                    FL\\d{1,}     \n","                    \"\"\", re.VERBOSE)\n","\n","\n","r_alt_2 = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d{0,2}[\\.\\,\\;]\n","                  \\d*\n","                  FT\n","                  \"\"\", re.VERBOSE)\n","\n","r_am_num = re.compile(r\"\"\"                      # RegEx for 'am' or 'AM' preceeded by numbers\n","                  (?i)                          # turns on the case-insensitive mode of RegEx                 \n","                  [0-1X\\w]{1,2}\n","                  [\\;\\:\\,\\.]*\n","                  [0-59]{1,2}\n","                  am                \n","                  \"\"\", re.VERBOSE)\n","\n","r_pm = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx                 \n","                  [0-1X\\w]{1,2}\n","                  [\\;\\:\\,\\.]*\n","                  [0-59]{1,2}\n","                  pm                \n","                  \"\"\", re.VERBOSE)\n","\n","r_dist_MI = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d                            # at least one digit, sticked to 'mi'\n","                  MI\n","                  \"\"\", re.VERBOSE)\n","\n","r_dist_SM = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d                            # at least one digit, sticked to 'mi'\n","                  SM\n","                  \"\"\", re.VERBOSE)\n","\n","r_dist_NM = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d                            # at least one digit, sticked to 'mi'\n","                  NM\n","                  \"\"\", re.VERBOSE)\n","\n","r_MIN = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d+                           # at least one digit. Without '+', it maches only '0minute' from '20minutes'\n","                  MINUTES                        \n","                  |\n","                  \\d+\n","                  MINUTE\n","                  |\n","                  \\d+\n","                  MINS\n","                  | \n","                  \\d+\n","                  MIN\n","                  \"\"\", re.VERBOSE)\n","\n","r_HR = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d+\n","                  HR                        \n","                  \"\"\", re.VERBOSE)\n","\n","r_LBS = re.compile(r\"\"\"\n","                  (?i)                          # turns on the case-insensitive mode of RegEx\n","                  \\d+\n","                  LBS                        \n","                  \"\"\", re.VERBOSE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G71ck_SNT_qC"},"outputs":[],"source":["# Define replacements to perform\n","# All the findings of the RegEx's in the list will be substituted by the corresponding key\n","# Note the precise use a spaces the substitute, to avoid problems during tokenization\n","my_dict = {\n","          ' <RUNWAY> ': [r_R_L_C, r_Right_Left_Center],\n","          ' <TEMP_C_NEG> ': [r_Celcius_neg],\n","          ' <TEMP_C_POS> ': [r_Celcius_degrees],\n","          ' Mach ': [r_Mach_1, r_Mach_2],\n","          ' <GUST> ': [r_gust],\n","          ' <TIME> ': [r_Z_1, r_Z_2],\n","          ' KT ': [r_KTS],\n","          ' FT ': [r_alt_1, r_alt_2],\n","          ' Ante_Meridiem ': [r_am_num],\n","          ' PM ': [r_pm],\n","          ' MI': [r_dist_MI],\n","          ' SM ': [r_dist_SM],\n","          ' NM ': [r_dist_NM],\n","          ' MIN': [r_MIN],           # NO space at the end of ' MIN'\n","          ' HR': [r_HR],             # NO space at the end of ' HR'\n","          ' LBS ': [r_LBS]\n","          }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpTp8WTAT_lW"},"outputs":[],"source":["def substitute_RegEx(my_dict):\n","  \"\"\"\n","  Inputs: a dictionnary with RegEx's and subsitutes\n","  Go through the narratives and replace the findings of the RegEx's by the substitutes \n","  passed as input (keys of the dictionnary).\n","  Write the new version of the narrative after the replacements into a new column of df \n","  entitled 'Narrative_RegEx_subst'.\n","  \"\"\"\n","  \n","  # Time function execution\n","  import time\n","  start_time = time.time()\n","  print(7*'-', \"Execution started, why don't you grab a coffee...\", 7*'-', '\\n')\n","\n","  # Copy the narratives into a new column\n","  df['Narrative_RegEx_subst'] = df['Narrative']\n","\n","  # Initialize counters\n","  repl_counter = 0\n","  progress = 0\n","\n","  # Loop through the narratives using their index (here ACN number)\n","  for idx in df['Narrative_RegEx_subst'].index:\n","    \n","    # Loop through the keys of the dict\n","    for k in my_dict.keys():  \n","      \n","      # Loop through the list of RegEx's that correspond to that key\n","      for regex in my_dict[k]:\n","        new_term = k\n","        repl_result = re.subn(regex, new_term, df['Narrative_RegEx_subst'].loc[idx])\n","        # The re.subn() method returns the new version of the target string after the replacements \n","        # The second element is the number of replacements it has made\n","    \n","        # New version of the narrative, after the replacements\n","        df['Narrative_RegEx_subst'][idx] = repl_result[0]\n","\n","        # Increment the counter of remplacements by the number of replacements done in the narrative\n","        repl_counter = repl_counter + repl_result[1]\n","      \n","    # Report on the execution progress  \n","    progress += 1\n","    if progress % 1000 == 0:\n","      print(f\"{progress} narratives processed; {repl_counter} replacements done so far \\n\")\n","\n","  end_time = time.time()\n","  print(f\"--- Executed in {np.round((end_time - start_time)/60,1)} minutes ---\")\n","  print(f\"{repl_counter} replacements in total\")\n","\n","  return None"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAXfSzqgUD3E","outputId":"c8773d23-5a1c-4fd0-aa44-acab87187f6d","executionInfo":{"status":"ok","timestamp":1658488046904,"user_tz":-180,"elapsed":2575916,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["------- Execution started, why don't you grab a coffee... ------- \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["1000 narratives processed; 784 replacements done so far \n","\n","2000 narratives processed; 1527 replacements done so far \n","\n","3000 narratives processed; 2386 replacements done so far \n","\n","4000 narratives processed; 3199 replacements done so far \n","\n","5000 narratives processed; 3869 replacements done so far \n","\n","6000 narratives processed; 4726 replacements done so far \n","\n","7000 narratives processed; 5541 replacements done so far \n","\n","8000 narratives processed; 6318 replacements done so far \n","\n","9000 narratives processed; 7206 replacements done so far \n","\n","10000 narratives processed; 8079 replacements done so far \n","\n","11000 narratives processed; 8880 replacements done so far \n","\n","12000 narratives processed; 9686 replacements done so far \n","\n","13000 narratives processed; 10552 replacements done so far \n","\n","14000 narratives processed; 11317 replacements done so far \n","\n","15000 narratives processed; 12104 replacements done so far \n","\n","16000 narratives processed; 12946 replacements done so far \n","\n","17000 narratives processed; 13750 replacements done so far \n","\n","18000 narratives processed; 14586 replacements done so far \n","\n","19000 narratives processed; 15409 replacements done so far \n","\n","20000 narratives processed; 16221 replacements done so far \n","\n","21000 narratives processed; 16942 replacements done so far \n","\n","22000 narratives processed; 17691 replacements done so far \n","\n","23000 narratives processed; 18504 replacements done so far \n","\n","24000 narratives processed; 19193 replacements done so far \n","\n","25000 narratives processed; 20000 replacements done so far \n","\n","26000 narratives processed; 20882 replacements done so far \n","\n","27000 narratives processed; 21691 replacements done so far \n","\n","28000 narratives processed; 22476 replacements done so far \n","\n","29000 narratives processed; 23267 replacements done so far \n","\n","30000 narratives processed; 23978 replacements done so far \n","\n","31000 narratives processed; 24739 replacements done so far \n","\n","32000 narratives processed; 25585 replacements done so far \n","\n","33000 narratives processed; 26358 replacements done so far \n","\n","34000 narratives processed; 27079 replacements done so far \n","\n","35000 narratives processed; 27801 replacements done so far \n","\n","36000 narratives processed; 28771 replacements done so far \n","\n","37000 narratives processed; 29621 replacements done so far \n","\n","38000 narratives processed; 30383 replacements done so far \n","\n","39000 narratives processed; 31236 replacements done so far \n","\n","40000 narratives processed; 32109 replacements done so far \n","\n","41000 narratives processed; 32937 replacements done so far \n","\n","42000 narratives processed; 33755 replacements done so far \n","\n","43000 narratives processed; 34548 replacements done so far \n","\n","44000 narratives processed; 35316 replacements done so far \n","\n","45000 narratives processed; 36120 replacements done so far \n","\n","46000 narratives processed; 36999 replacements done so far \n","\n","47000 narratives processed; 37827 replacements done so far \n","\n","48000 narratives processed; 38667 replacements done so far \n","\n","49000 narratives processed; 39403 replacements done so far \n","\n","50000 narratives processed; 39865 replacements done so far \n","\n","51000 narratives processed; 40333 replacements done so far \n","\n","52000 narratives processed; 40781 replacements done so far \n","\n","53000 narratives processed; 42018 replacements done so far \n","\n","54000 narratives processed; 43254 replacements done so far \n","\n","55000 narratives processed; 44111 replacements done so far \n","\n","56000 narratives processed; 44579 replacements done so far \n","\n","57000 narratives processed; 44954 replacements done so far \n","\n","58000 narratives processed; 45445 replacements done so far \n","\n","59000 narratives processed; 46829 replacements done so far \n","\n","60000 narratives processed; 48223 replacements done so far \n","\n","61000 narratives processed; 49372 replacements done so far \n","\n","62000 narratives processed; 49829 replacements done so far \n","\n","63000 narratives processed; 50290 replacements done so far \n","\n","64000 narratives processed; 51714 replacements done so far \n","\n","65000 narratives processed; 53093 replacements done so far \n","\n","66000 narratives processed; 54891 replacements done so far \n","\n","67000 narratives processed; 55279 replacements done so far \n","\n","68000 narratives processed; 55721 replacements done so far \n","\n","69000 narratives processed; 57232 replacements done so far \n","\n","70000 narratives processed; 58311 replacements done so far \n","\n","71000 narratives processed; 59509 replacements done so far \n","\n","72000 narratives processed; 60820 replacements done so far \n","\n","73000 narratives processed; 62122 replacements done so far \n","\n","74000 narratives processed; 63476 replacements done so far \n","\n","75000 narratives processed; 64448 replacements done so far \n","\n","76000 narratives processed; 64837 replacements done so far \n","\n","77000 narratives processed; 65141 replacements done so far \n","\n","78000 narratives processed; 66112 replacements done so far \n","\n","79000 narratives processed; 67483 replacements done so far \n","\n","80000 narratives processed; 68717 replacements done so far \n","\n","81000 narratives processed; 69987 replacements done so far \n","\n","82000 narratives processed; 71235 replacements done so far \n","\n","83000 narratives processed; 72673 replacements done so far \n","\n","84000 narratives processed; 73745 replacements done so far \n","\n","85000 narratives processed; 74931 replacements done so far \n","\n","86000 narratives processed; 76112 replacements done so far \n","\n","87000 narratives processed; 77521 replacements done so far \n","\n","88000 narratives processed; 78501 replacements done so far \n","\n","89000 narratives processed; 79394 replacements done so far \n","\n","90000 narratives processed; 80203 replacements done so far \n","\n","91000 narratives processed; 81211 replacements done so far \n","\n","92000 narratives processed; 82118 replacements done so far \n","\n","93000 narratives processed; 82902 replacements done so far \n","\n","94000 narratives processed; 84298 replacements done so far \n","\n","95000 narratives processed; 85662 replacements done so far \n","\n","96000 narratives processed; 87068 replacements done so far \n","\n","97000 narratives processed; 88335 replacements done so far \n","\n","--- Executed in 42.9 minutes ---\n","88875 replacements in total\n"]}],"source":["# Call the function\n","# /!\\ takes about 50min. to execute!\n","substitute_RegEx(my_dict)"]},{"cell_type":"markdown","source":["#### AM & IF special treatment"],"metadata":{"id":"C5iqrRQIUr16"}},{"cell_type":"markdown","source":["We have treated 'am' preceeded by numeric values above.\n","Here, we treat the uppercase form 'AM', only in the narratives >= 2009, which are written in lowercase, except some uppercase abbreviations, such as 'AM'.\n","\n","The same holds true for 'IF', which means 'Intermediate Fix'"],"metadata":{"id":"HaLpaFXwa9rH"}},{"cell_type":"code","source":["r_AM_2009 = re.compile(r\"\"\"\n","                  [\\s\\.\\,\\;\\:\\/]\n","                  AM\n","                  [\\s\\.\\,\\;\\:\\/]\n","                \"\"\", re.VERBOSE)\n","\n","# \"Intermediate Fix\" abbreviation\n","r_IF = re.compile(r\"\"\"\n","                  [\\s\\.\\,\\;\\:\\/]\n","                  IF\n","                  [\\s\\.\\,\\;\\:\\/]\n","                  \"\"\", re.VERBOSE)\n","\n","# Define replacements to perform\n","# All the findings of the RegEx's in the list will be substituted by the corresponding key\n","# Note the precise use a spaces the substitute, to avoid problems during tokenization\n","my_dict_2009 = {\n","          ' Ante_Meridiem ': [r_AM_2009],\n","                  ' <IF> ' : [r_IF]  # it actually means 'Intermediate Fix'\n","          }"],"metadata":{"id":"pmSh_icnU7uJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def substitute_RegEx_AM_IF(my_dict):\n","  \"\"\"\n","  DEALS SPECIFICALLY WITH 'AM' - 'Ante Meridiem' and 'IF' - 'Intermediate Fix'\n","  on narratives >= 2009 ONLY!\n","\n","  Inputs: a dictionnary with RegEx's and subsitutes\n","  Go through the narratives and replace the findings of the RegEx's by the substitutes \n","  passed as input (keys of the dictionnary).\n","  Write the new version of the narrative after the replacements into a new column of df \n","  entitled 'Narrative_RegEx_subst'.\n","  \"\"\"\n","  \n","  # Time function execution\n","  import time\n","  start_time = time.time()\n","  print(7*'-', \"Execution started, why don't you grab a coffee...\", 7*'-', '\\n')\n","\n","  # # Copy the narratives into a new column\n","  # df['Narrative_RegEx_subst'] = df['Narrative']\n","\n","  # Initialize counters\n","  repl_counter = 0\n","  progress = 0\n","\n","  # Loop through the narratives AFTER 2009, using their index (here ACN number)\n","  for idx in df[df['Year']>=2009]['Narrative_RegEx_subst'].index:\n","    \n","    # Loop through the keys of the dict\n","    for k in my_dict.keys():  \n","      \n","      # Loop through the list of RegEx's that correspond to that key\n","      for regex in my_dict[k]:\n","        new_term = k\n","        repl_result = re.subn(regex, new_term, df['Narrative_RegEx_subst'].loc[idx])\n","        # The re.subn() method returns the new version of the target string after the replacements \n","        # The second element is the number of replacements it has made\n","    \n","        # New version of the narrative, after the replacements\n","        df['Narrative_RegEx_subst'][idx] = repl_result[0]\n","\n","        # Increment the counter of remplacements by the number of replacements done in the narrative\n","        repl_counter = repl_counter + repl_result[1]\n","      \n","    # Report on the execution progress  \n","    progress += 1\n","    if progress % 1000 == 0:\n","      print(f\"{progress} narratives processed; {repl_counter} replacements done so far \\n\")\n","\n","  end_time = time.time()\n","  print(f\"--- Executed in {np.round((end_time - start_time)/60,1)} minutes ---\")\n","  print(f\"{repl_counter} replacements in total\")\n","\n","  return None"],"metadata":{"id":"66gMOHr6UWcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the function a 2nd time, for 'AM'\n","# /!\\ takes about 50min. to execute!\n","substitute_RegEx_AM_IF(my_dict_2009)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8hCruhzUmjj","executionInfo":{"status":"ok","timestamp":1658488186307,"user_tz":-180,"elapsed":139413,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"1436ab92-f5ad-409d-dcd5-0f3d67bb9f78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------- Execution started, why don't you grab a coffee... ------- \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["1000 narratives processed; 5 replacements done so far \n","\n","2000 narratives processed; 15 replacements done so far \n","\n","3000 narratives processed; 26 replacements done so far \n","\n","4000 narratives processed; 34 replacements done so far \n","\n","5000 narratives processed; 40 replacements done so far \n","\n","6000 narratives processed; 47 replacements done so far \n","\n","7000 narratives processed; 58 replacements done so far \n","\n","8000 narratives processed; 67 replacements done so far \n","\n","9000 narratives processed; 74 replacements done so far \n","\n","10000 narratives processed; 81 replacements done so far \n","\n","11000 narratives processed; 82 replacements done so far \n","\n","12000 narratives processed; 88 replacements done so far \n","\n","13000 narratives processed; 92 replacements done so far \n","\n","14000 narratives processed; 93 replacements done so far \n","\n","15000 narratives processed; 99 replacements done so far \n","\n","16000 narratives processed; 100 replacements done so far \n","\n","17000 narratives processed; 101 replacements done so far \n","\n","18000 narratives processed; 108 replacements done so far \n","\n","19000 narratives processed; 113 replacements done so far \n","\n","20000 narratives processed; 121 replacements done so far \n","\n","21000 narratives processed; 122 replacements done so far \n","\n","22000 narratives processed; 124 replacements done so far \n","\n","23000 narratives processed; 130 replacements done so far \n","\n","24000 narratives processed; 136 replacements done so far \n","\n","25000 narratives processed; 139 replacements done so far \n","\n","26000 narratives processed; 142 replacements done so far \n","\n","27000 narratives processed; 148 replacements done so far \n","\n","28000 narratives processed; 152 replacements done so far \n","\n","29000 narratives processed; 154 replacements done so far \n","\n","30000 narratives processed; 157 replacements done so far \n","\n","31000 narratives processed; 157 replacements done so far \n","\n","32000 narratives processed; 162 replacements done so far \n","\n","33000 narratives processed; 167 replacements done so far \n","\n","34000 narratives processed; 171 replacements done so far \n","\n","35000 narratives processed; 183 replacements done so far \n","\n","36000 narratives processed; 196 replacements done so far \n","\n","37000 narratives processed; 201 replacements done so far \n","\n","38000 narratives processed; 202 replacements done so far \n","\n","39000 narratives processed; 215 replacements done so far \n","\n","40000 narratives processed; 227 replacements done so far \n","\n","41000 narratives processed; 230 replacements done so far \n","\n","42000 narratives processed; 234 replacements done so far \n","\n","43000 narratives processed; 238 replacements done so far \n","\n","44000 narratives processed; 242 replacements done so far \n","\n","45000 narratives processed; 251 replacements done so far \n","\n","46000 narratives processed; 258 replacements done so far \n","\n","47000 narratives processed; 265 replacements done so far \n","\n","48000 narratives processed; 274 replacements done so far \n","\n","49000 narratives processed; 276 replacements done so far \n","\n","50000 narratives processed; 302 replacements done so far \n","\n","51000 narratives processed; 306 replacements done so far \n","\n","52000 narratives processed; 311 replacements done so far \n","\n","53000 narratives processed; 328 replacements done so far \n","\n","54000 narratives processed; 333 replacements done so far \n","\n","--- Executed in 2.3 minutes ---\n","335 replacements in total\n"]}]},{"cell_type":"markdown","metadata":{"id":"_GuC16ZOV4sJ"},"source":["### Save the output externally"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAV3hIiEV7IR","outputId":"d33fbc7f-150e-445b-98a8-93ff311ef842","executionInfo":{"status":"ok","timestamp":1658488186976,"user_tz":-180,"elapsed":685,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/transformed\n"]}],"source":["##########################################################\n","# WARNING!! \n","# If you execute this cell, you will OVERWRITTE the data!\n","##########################################################\n","\n","%cd /content/drive/MyDrive/data/transformed/\n","\n","# save the df['Narrative_RegEx_subst'] externally to avoid having to perform the \n","# substitutions again\n","with open(\"Narrative_RegEx_subst_21072022_TRAIN.pkl\", \"wb\") as f:\n","    pkl.dump([df['Narrative_RegEx_subst']], f) # saves the variables into a list"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["tAJ40jap2rBh","BfmhmLv0_Osg"],"provenance":[{"file_id":"1qhXdYmJvtunv1bhivEwdLB9bbYKeIMoX","timestamp":1656941850410},{"file_id":"1rtxLNDvVau-UYbcAkUcA0GUgc78nRgIq","timestamp":1656586559783}],"toc_visible":true,"authorship_tag":"ABX9TyPF9s9INBx/VHhnthA5TOHM"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}