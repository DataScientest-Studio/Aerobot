{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["BfmhmLv0_Osg","E-BJjgcY2rE6","WD2PuNqcDrDA","fG0TVOvK2q8X","SQK0xxmc2q0Y","IgO-OOQT4Bdh"],"authorship_tag":"ABX9TyPIoUvNgzjkoqBOCtW+J0Rw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ABOUT"],"metadata":{"id":"a59UKY4T2lk_"}},{"cell_type":"markdown","source":["\n","Datascientest's Datascientist continuous bootcamp - cohorte Mars2022 -  AeroBOT project\n","\n","**Tutor**\n","\n","* Alban THUET\n","\n","**Authors:**\n","\n","* Hélène ASSIR\n","* Hichem HADJI  \n","* [Ioannis STASINOPOULOS](https://www.linkedin.com/in/ioannis-stasinopoulos/)\n","\n","</br>\n","\n","---\n","</br>\n","\n","**Version History**\n","\n","Version | Date       | Author(s)  | Modification\n","--------|----------- | ---------  | --------------------------\n","X.X     | XX/XX/2022 | X.X        | modif\n","1.0     | 21/07/2022 | I.S, H.A.  | Document creation"],"metadata":{"id":"TDPK0egXZHoa"}},{"cell_type":"markdown","source":["This notebook \n","\n","\n","*   loads the raw data donwloaded from the ASRS in to a pandas DataFrame (total of `108407` entries)\n","*   removes 2 columns named 'Unnammed: ...' that originate from the concatenation of several .csv files into the `ASRS_20y_data.csv` file\n","* removes the 166 data related to UAS\n","* removes the UAS-related columns (features) \n","* allocates 10% (i.e. `10824` entries) of the total number of entries to a test set. *In the test set only entries after 2010 are present!*\n","Why? This test set emulates new data that will arrive after 2022. Helene observed that Narratives were written in uppercase letters before 2010.\n","The resulting train set contains `97417` entries and 96 columns\n","* saves the train and test sets as .pkl files, named `train_data_final.pkl `and `test_data_final.pkl`, respectively. \n","Further processing of the data should be perfomed on the `train_data_final.pkl ` data."],"metadata":{"id":"LQnfHCJnZXLA"}},{"cell_type":"markdown","source":["# IMPORT PACKAGES\n"],"metadata":{"id":"tAJ40jap2rBh"}},{"cell_type":"code","source":["#######################\n","# Import packages\n","#######################\n","import numpy as np\n","import seaborn as sns\n","\n","import pandas as pd\n","# Set pandas settings to show all data when using .head(), .columns etc.\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = None\n","\n","import itertools # Pour créer des iterateurs\n","\n","######################\n","# PLOTTING\n","######################\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# Define global plot parameters for better readability and consistency among plots\n","# A complete list of the rcParams keys can be retrieved via plt.rcParams.keys() function\n","plt.rcParams['axes.titlesize'] = 30\n","plt.rcParams['axes.labelsize'] = 23\n","plt.rcParams['xtick.labelsize'] = 23\n","plt.rcParams['ytick.labelsize'] = 23\n","plt.rc('legend', fontsize=23)    # legend fontsize\n","\n","# BOKEH \n","from bokeh.plotting import figure # Importation de la classe figure qui permet de créer un graphique bokeh.\n","from bokeh.io import  push_notebook, output_notebook, show\n","output_notebook() # permet d'afficher tous les futurs graphiques dans l'output d'une cellule jupyter. Si cette instruction n'est pas lancée, la figure s'affichera dans un nouvel onglet.\n","from bokeh.models import ColumnDataSource\n","from bokeh.transform import dodge\n","from bokeh.models.tools import HoverTool\n","\n","#####################\n","# NLP \n","#####################\n","import re # for Regular Expression handling\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet') # WordNet lemmatizer\n","nltk.download('omw-1.4') # necessary for WordNet lemmatizer\n","from nltk.tokenize import word_tokenize # Usual tokenizer\n","from nltk.tokenize import TweetTokenizer # Special tokenizer;  \"we'll\", \"didn't\", etc. are considered as one word\n","from sklearn.feature_extraction.text import CountVectorizer # Vectorization\n","from nltk.corpus import stopwords # Import stopwords from nltk.corpus\n","\n","###############################\n","# ML preprocessing and models\n","###############################\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","import pickle as pkl # Saving data externally"],"metadata":{"id":"5_efzqI3_FPo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585816782,"user_tz":-120,"elapsed":204,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"11468f0d-182b-4de1-efb8-a16478251e6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["# LOAD DATA"],"metadata":{"id":"cjRrSdqQ7llR"}},{"cell_type":"markdown","source":["## Mount GDrive"],"metadata":{"id":"BfmhmLv0_Osg"}},{"cell_type":"code","source":["# Mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#check your present working directory \n","%pwd"],"metadata":{"id":"N_mjKklM_bJH","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1656585818348,"user_tz":-120,"elapsed":1381,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"1db94730-3115-4a98-d13a-ca79c4314b3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/data'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["# move to the desired location (adapt to your folder-tree-structure):\n","%cd /content/drive/MyDrive/data/"],"metadata":{"id":"S72xAGPS_bGM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585818349,"user_tz":-120,"elapsed":13,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"5b20f935-386e-4496-e752-d95b2cfaaa8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data\n"]}]},{"cell_type":"code","source":["!ls # list the content of the pwd\n","\n","#!ls \"/content/drive/MyDrive/Data_Science/Formations/DataScienceTest/projet/AeroBot/\" # list contect of a speficic folder"],"metadata":{"id":"NkiTSU2c_bDh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585818620,"user_tz":-120,"elapsed":280,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"b64d660f-7794-4cbc-b68a-3073b091c9a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" ASRS_20y_data.csv\t        State_Reference_Dictionnary.csv\n","'Data Dictionnary themes.csv'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"p34khfQu_bBK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load the ASRS_20y_data.csv data\n","\n","\n"],"metadata":{"id":"E-BJjgcY2rE6"}},{"cell_type":"code","source":["df = pd.read_csv('ASRS_20y_data.csv', low_memory=False,index_col=1)\n","# See https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options"],"metadata":{"id":"_-27StNe_M1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"A total of\", len(df), \"entries have been loaded.\")"],"metadata":{"id":"Q-knL3JM_Uml","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585828796,"user_tz":-120,"elapsed":298,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"96a1201e-3a81-47cb-edca-16fbf78f6e05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["A total of 108407 entries have been loaded.\n"]}]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"4sHOePlHEJ9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585828797,"user_tz":-120,"elapsed":11,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"f52b494f-4d28-424d-ea15-e53fd7fb3fde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Date', 'Local Time Of Day', 'Locale Reference',\n","       'State Reference', 'Relative Position.Angle.Radial',\n","       'Relative Position.Distance.Nautical Miles',\n","       'Altitude.AGL.Single Value', 'Altitude.MSL.Single Value',\n","       'Latitude / Longitude (UAS)',\n","       ...\n","       'When Detected', 'Result', 'Contributing Factors / Situations',\n","       'Primary Problem', 'Narrative', 'Callback', 'Narrative.1', 'Callback.1',\n","       'Synopsis', 'Unnamed: 125'],\n","      dtype='object', length=126)"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPaqBQjAD_Oe","executionInfo":{"status":"ok","timestamp":1656585828797,"user_tz":-120,"elapsed":7,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"591df6ea-50c3-416e-e0b1-2f735ce76ff8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(108407, 126)"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","source":["## Remove empty columns"],"metadata":{"id":"WD2PuNqcDrDA"}},{"cell_type":"code","source":["# Remove Unnamed columns\n","df = df.drop(['Unnamed: 0','Unnamed: 125'], axis = 1)    \n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"s8nOSBZ9DxRn","executionInfo":{"status":"error","timestamp":1664356956499,"user_tz":-120,"elapsed":10,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"b66c9728-0fad-4a13-cc34-2c44198b5c50"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c680a6931008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove Unnamed columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Unnamed: 125'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"markdown","source":["## Remove UAS entries"],"metadata":{"id":"fG0TVOvK2q8X"}},{"cell_type":"code","source":["UAS_column_list=[]\n","for col in df.columns:\n","  if 'UAS' in col :\n","    UAS_column_list.append(col)"],"metadata":{"id":"aaBDrxQ5AFIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["UAS_column_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ppse0PNdEhEV","executionInfo":{"status":"ok","timestamp":1656585828974,"user_tz":-120,"elapsed":9,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"cc7e4cee-9c0e-413f-9b8f-ef4a84ebfeac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Latitude / Longitude (UAS)',\n"," 'Airspace Authorization Provider (UAS)',\n"," 'Operating Under Waivers / Exemptions / Authorizations (UAS)',\n"," 'Waivers / Exemptions / Authorizations (UAS)',\n"," 'Airworthiness Certification (UAS)',\n"," 'Weight Category (UAS)',\n"," 'Configuration (UAS)',\n"," 'Flight Operated As (UAS)',\n"," 'Flight Operated with Visual Observer (UAS)',\n"," 'Control Mode (UAS)',\n"," 'Flying In / Near / Over (UAS)',\n"," 'Passenger Capable (UAS)',\n"," 'Type (UAS)',\n"," 'Number of UAS Being Controlled (UAS)',\n"," 'Airspace Authorization Provider (UAS).1',\n"," 'Operating Under Waivers / Exemptions / Authorizations (UAS).1',\n"," 'Waivers / Exemptions / Authorizations (UAS).1',\n"," 'Airworthiness Certification (UAS).1',\n"," 'Weight Category (UAS).1',\n"," 'Configuration (UAS).1',\n"," 'Flight Operated As (UAS).1',\n"," 'Flight Operated with Visual Observer (UAS).1',\n"," 'Control Mode (UAS).1',\n"," 'Flying In / Near / Over (UAS).1',\n"," 'Passenger Capable (UAS).1',\n"," 'Type (UAS).1',\n"," 'Number of UAS Being Controlled (UAS).1',\n"," 'UAS Communication Breakdown',\n"," 'UAS Communication Breakdown.1']"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["# Remove entries with non empty UAS columns\n","for col_UAS in  UAS_column_list:\n","    df = df[df[col_UAS].isnull()]\n","df.shape"],"metadata":{"id":"cjqeaHVm_1N5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585834978,"user_tz":-120,"elapsed":6011,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"274284df-e164-4ab1-863c-64ead204e95f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(108241, 124)"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["# Remove UAS columns\n","df = df.drop(UAS_column_list, axis = 1)    \n","df.shape"],"metadata":{"id":"kDgBO2eB_3m5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656585835253,"user_tz":-120,"elapsed":280,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"dc7a9e5b-59db-4e6f-9b48-0872ead9122a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(108241, 95)"]},"metadata":{},"execution_count":119}]},{"cell_type":"markdown","source":["**Yannis checks one RegEx**\n","\n","---\n","\n","\n","\n"],"metadata":{"id":"Ttxa8eEs3jwC"}},{"cell_type":"markdown","source":["## Split into TRAIN, VALIDATION, TEST sets\n"],"metadata":{"id":"SQK0xxmc2q0Y"}},{"cell_type":"markdown","source":["\n","*   the test set emulates the future data that we will get. It is set completely aside\n","\n"],"metadata":{"id":"XfbISXSa4xOz"}},{"cell_type":"markdown","source":["### Create 'Year' feature"],"metadata":{"id":"IgO-OOQT4Bdh"}},{"cell_type":"code","source":["df['Year']=df.Date.astype(str).apply(lambda x :  x if  len(x)==4 else x[:-2] ).astype(int) "],"metadata":{"id":"mCF-r2RE2pnY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sub-df containing entries from years 2010 (to early 2022)\n","df_recent = df[df['Year'] >= 2010]\n","\n","my_test_size = int(np.round(0.1 * len(df), 0))\n","print(\"We have a total of\", len(df), 'entries.')\n","print(\"We allocate 10% of the total number of entries to the test set; this amounts to:\", my_test_size, 'entries.')\n","\n","df_recent_train, df_test = train_test_split(df_recent ,test_size=my_test_size,random_state=1234)\n","print(\"We have \", len(df_test), 'entries in our test set')\n","\n","df_train=pd.concat ([df_recent_train, df[df['Year'] < 2010]]) \n","print(\"We have \", len(df_train), 'entries in our train set')\n","df_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S71IcNYfGm0u","executionInfo":{"status":"ok","timestamp":1656585835778,"user_tz":-120,"elapsed":529,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"outputId":"3d1dc9e5-0ecb-4d28-8668-eb9c9df4156b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We have a total of 108241 entries.\n","We allocate 10% of the total number of entries to the test set; this amounts to: 10824 entries.\n","We have  10824 entries in our test set\n","We have  97417 entries in our train set\n"]},{"output_type":"execute_result","data":{"text/plain":["(97417, 96)"]},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","source":["## Save / Load datasets\n"],"metadata":{"id":"pB8SGMTD4JsN"}},{"cell_type":"code","source":["##########################################################\n","# WARNING!! \n","# If you execute this cell, you will OVERWRITTE the data!\n","##########################################################\n","\n","# %cd /content/drive/MyDrive/data/transformed/\n","\n","# #to save the data\n","# # Save TEST data\n","# with open(\"test_data_final.pkl\", \"wb\") as f:\n","#     pkl.dump([df_test], f) # saves the variables into a list\n","\n","# # Save TRAIN data\n","# with open(\"train_data_final.pkl\", \"wb\") as f:\n","#     pkl.dump([df_train], f) # saves the variables into a list"],"metadata":{"id":"aRaL1efT4c9P","executionInfo":{"status":"ok","timestamp":1656586127274,"user_tz":-120,"elapsed":1552,"user":{"displayName":"Project Datascientest","userId":"15618889726029501374"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6bfcfc8-cf49-4c50-df9f-9f871be2155f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/transformed\n"]}]}]}